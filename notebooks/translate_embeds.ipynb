{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "695333fe-b2e6-40ac-b03a-8b44c2b540a2",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8e5d032-6bb3-47a4-b3a7-829d04ceda98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/dagarwal_umass_edu/.conda/envs/lapeft/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5EncoderModel, T5ForConditionalGeneration, T5Config, AutoModelForCausalLM, \\\n",
    "    AutoTokenizer, T5Tokenizer, TrainingArguments, Trainer, DataCollator, DataCollatorForLanguageModeling, DataCollatorForSeq2Seq, DataCollatorWithPadding, get_scheduler, \\\n",
    "    EarlyStoppingCallback, IntervalStrategy, TrainerCallback, LlamaConfig \n",
    "from torch.nn.functional import cosine_similarity\n",
    "from datasets import Dataset, DatasetDict\n",
    "from peft import  get_peft_model, PromptTuningConfig, MultitaskPromptTuningConfig, TaskType, PromptTuningInit, PeftModel\n",
    "import schedulefree\n",
    "import torch\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from IPython import embed\n",
    "import numpy as np\n",
    "import wandb\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "103f4fc9-1bac-4d84-8a2f-377e44e1b17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = \"./\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02d343cc-cfbf-4f65-9828-74e66e636efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstrainedAdamW(torch.optim.AdamW):\n",
    "    \"\"\"\n",
    "    A variant of Adam where some of the parameters are constrained to have unit norm.\n",
    "    \"\"\"\n",
    "    def __init__(self, params, constrained_params, lr, scale_factor=1., weight_decay=0.0):\n",
    "        super().__init__(params, lr=lr, weight_decay=weight_decay)\n",
    "        self.constrained_params = list(constrained_params)\n",
    "        self.scale_factor = scale_factor\n",
    "    \n",
    "    def step(self, closure=None):\n",
    "        with torch.no_grad():\n",
    "            for i,p in enumerate(self.constrained_params):\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                if i < 2:  # Handle low-d vtoken and projection matrix differently\n",
    "                    normed_p = p / p.norm(dim=-1, keepdim=True) * self.scale_factor  # normed_p = p / p.norm() * self.scale_factor  # p.norm(dim=0, keepdim=True)\n",
    "                    # project away the parallel component of the gradient\n",
    "                    p.grad -= (p.grad * normed_p).sum(dim=-1, keepdim=True) * normed_p  # (dim=0, keepdim=True)\n",
    "                else:\n",
    "                    normed_p = p / p.norm(dim=0, keepdim=True) * self.scale_factor\n",
    "                    p.grad -= (p.grad * normed_p).sum(dim=0, keepdim=True) * normed_p\n",
    "        super().step(closure=closure)\n",
    "        with torch.no_grad():\n",
    "            for i,p in enumerate(self.constrained_params):\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                # renormalize the constrained parameters\n",
    "                if i < 2:\n",
    "                    p /= p.norm(dim=-1, keepdim=True) * self.scale_factor  # p /= p.norm() * self.scale_factor  # p.norm(dim=0, keepdim=True)\n",
    "                else:\n",
    "                    p /= p.norm(dim=0, keepdim=True) * self.scale_factor\n",
    "\n",
    "class ConstrainedAdamWScheduleFree(schedulefree.AdamWScheduleFree):\n",
    "    \"\"\"\n",
    "    A variant of Adam where some of the parameters are constrained to have unit norm.\n",
    "    \"\"\"\n",
    "    def __init__(self, params, constrained_params, lr, warmup_steps=100):\n",
    "        super().__init__(params, lr=lr, warmup_steps=warmup_steps)\n",
    "        self.constrained_params = list(constrained_params)\n",
    "    \n",
    "    def step(self, closure=None):\n",
    "        with torch.no_grad():\n",
    "            for p in self.constrained_params:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                normed_p = p / p.norm(dim=-1, keepdim=True)  # normed_p = p / p.norm() # p.norm(dim=0, keepdim=True)\n",
    "                # project away the parallel component of the gradient\n",
    "                p.grad -= (p.grad * normed_p).sum(dim=-1, keepdim=True) * normed_p  # .sum(dim=0, keepdim=True)\n",
    "        super().step(closure=closure)\n",
    "        with torch.no_grad():\n",
    "            for p in self.constrained_params:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                # renormalize the constrained parameters\n",
    "                p /= p.norm(dim=-1, keepdim=True)  # p /= p.norm() # p.norm(dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61babbef-56b3-4dda-a710-60866ac1c6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/twentyquestions/datasets/word2vec-2000/computer.csv', 'r') as fh:\n",
    "    words = pd.read_csv(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d2191f4-0a27-4600-993a-f901cc512fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [f\"The task is to find a hidden test word by guessing new words. What is your next guess?\" for x in words[\"Words\"]]\n",
    "targets = [f\"{x}\" for x in words[\"Words\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b91c9a6-e81d-4aa2-a17a-9f6dc63ac636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert embeddings to a list of lists\n",
    "# feats = torch.load(\"../cache/word2vec-2000/computer/computer_word_average_t5-base_feats.bin\")\n",
    "# feats_list = [feat.tolist() for feat in feats]\n",
    "# Create a dictionary with the data\n",
    "data_dict = {\n",
    "    # 'inputs_embeds': feats_list,\n",
    "    'prompt': prompts,\n",
    "    'target': targets,\n",
    "    'task_ids': list(range(len(prompts)))\n",
    "}\n",
    "# Create a Dataset\n",
    "dataset = Dataset.from_dict(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "279ea3c6-8dd7-441f-a33d-ae489fd8c608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenized_dataset(tokenizer, shuffle_input=False, shuffle_dataset=False, constant_input=None, seed=17):\n",
    "    # Load dataset\n",
    "#     hf_dataset = datasets.Dataset.from_pandas(pd.DataFrame(data=raw_dataset))\n",
    "    hf_dataset = dataset\n",
    "    if not MODEL_NAME.startswith('t5'):\n",
    "        pass\n",
    "        hf_dataset = hf_dataset.map(lambda x: tokenizer(x[\"prompt\"], text_target=x[\"target\"]))\n",
    "        need_eos = hf_dataset[0][\"input_ids\"][-1] != tokenizer.eos_token_id\n",
    "        hf_dataset = hf_dataset.map(lambda x: {\n",
    "            **x,\n",
    "            \"input_ids\": x[\"input_ids\"] + x[\"labels\"][1 if x[\"labels\"][0] == tokenizer.bos_token_id else 0:] + ([tokenizer.eos_token_id] if need_eos else []),\n",
    "            \"attention_mask\": [1] * len(x[\"attention_mask\"]) + [1] * len(x[\"labels\"][1 if x[\"labels\"][0] == tokenizer.bos_token_id else 0:]) + (\n",
    "                [1] if need_eos else []),\n",
    "            \"labels\": [-100] * len(x[\"input_ids\"]) + x[\"labels\"][1 if x[\"labels\"][0] == tokenizer.bos_token_id else 0:] + (\n",
    "                [tokenizer.eos_token_id] if need_eos else [])\n",
    "        })\n",
    "        # if shuffle_input:\n",
    "        #     random.seed(seed)\n",
    "        #     hf_dataset = hf_dataset.map(lambda x: {**x, \"input_ids\": random.sample(x[\"input_ids\"], len(x[\"input_ids\"]))})\n",
    "        # if constant_input is not None:\n",
    "        #     hf_dataset = hf_dataset.map(lambda x: {**x, \"input_ids\": [constant_input]*len(x[\"input_ids\"])})\n",
    "        # hf_dataset = hf_dataset.map(lambda x: {**x, \"input_ids\": x[\"input_ids\"] + x[\"labels\"] + [tokenizer.eos_token_id],\n",
    "        #                                        \"attention_mask\": x[\"attention_mask\"] + [1]*len(x[\"labels\"]) + [1],\n",
    "        #                                        \"labels\": [-100]*len(x[\"input_ids\"]) + x[\"labels\"] + [tokenizer.eos_token_id]})\n",
    "        # hf_dataset = hf_dataset.map(lambda x: tokenizer(x[\"prompt\"] + \" \" + x[\"target\"]))\n",
    "        # hf_dataset = hf_dataset.map(lambda x: {**x, \"input_ids\": x[\"input_ids\"]+[tokenizer.eos_token_id], \"attention_mask\": x[\"attention_mask\"]+[1]})\n",
    "    else:\n",
    "        # Use below for translation embeddings\n",
    "        # hf_dataset = hf_dataset.map(lambda x: tokenizer(x[\"prompt\"], text_target=x[\"prompt\"].split()[-1]))\n",
    "        \n",
    "        # Use below to test with text tokens\n",
    "        # hf_dataset = hf_dataset.map(lambda x: tokenizer(\" \".join(x[\"prompt\"].split()[:-1]), text_target=x[\"prompt\"].split()[-1]))\n",
    "\n",
    "        # Use below to test with no prompt\n",
    "        # hf_dataset = hf_dataset.map(lambda x: tokenizer(\"Instruction\", text_target=x[\"prompt\"].split()[-1]))\n",
    "        hf_dataset = hf_dataset.map(lambda x: tokenizer(x[\"prompt\"], text_target=x[\"target\"]))\n",
    "        # hf_dataset = hf_dataset.map(lambda x: {**x, \"attention_mask\": [0]*len(x[\"attention_mask\"])})  # Don't attend to the encoder input tokens (only attend to the encoder virtual token)\n",
    "    \n",
    "    if shuffle_dataset:\n",
    "        hf_dataset = hf_dataset.shuffle(seed=seed)\n",
    "    \n",
    "    return hf_dataset\n",
    "\n",
    "\n",
    "def get_prompt_embed(hf_dataset, foundational_model, tokenizer, custom_prompt=None):\n",
    "    token_embeds = foundational_model.get_input_embeddings()\n",
    "    for p in token_embeds.parameters():\n",
    "        break\n",
    "\n",
    "    if custom_prompt is not None:\n",
    "        prompt_input_ids = tokenizer(custom_prompt)['input_ids']\n",
    "        if not MODEL_NAME.startswith('t5') and prompt_input_ids[-1] == tokenizer.eos_token_id:\n",
    "            prompt_input_ids = prompt_input_ids[:-1]\n",
    "    else:\n",
    "        # Based on prompt input_ids (assumes every prompt input is the same)\n",
    "        if MODEL_NAME.startswith('t5'):\n",
    "            prompt_input_ids = hf_dataset[0]['input_ids']  # encoder input\n",
    "        else:\n",
    "            prompt_input_ids = hf_dataset[0]['input_ids'][:hf_dataset[0]['labels'].count(-100)]  # inputs for which no predictions need to be made\n",
    "    prompt_embed = p[prompt_input_ids][None, :, :]\n",
    "    return prompt_embed\n",
    "    \n",
    "\n",
    "class DataCollatorForSeq2SeqWithEmbeddings(DataCollatorForSeq2Seq):\n",
    "    def __call__(self, features, return_tensors=None):\n",
    "        super_keys = ['input_ids', 'labels']\n",
    "        batch = super().__call__([{_k:_v for _k,_v in f.items() if _k in super_keys} for f in features], return_tensors)\n",
    "        inputs_embeds = torch.tensor([f[\"inputs_embeds\"] for f in features], dtype=torch.float)[:, None, :]\n",
    "        task_ids = torch.tensor([f[\"task_ids\"] for f in features], dtype=torch.long)\n",
    "        # prompts = torch.tensor([f[\"prompts\"] for f in features], dtype=torch.long)\n",
    "        # return {\"inputs_embeds\": inputs_embeds, \"prompts\": prompts}\n",
    "        rtn = {\"labels\": batch[\"labels\"], \"inputs_embeds\": inputs_embeds, \"task_ids\": task_ids}\n",
    "        return rtn\n",
    "\n",
    "\n",
    "class CustomDataCollatorForSeq2Seq(DataCollatorForSeq2Seq):\n",
    "    def __call__(self, features, return_tensors=None):\n",
    "        super_keys = ['input_ids', 'attention_mask', 'labels']\n",
    "        batch = super().__call__([{_k:_v for _k,_v in f.items() if _k in super_keys} for f in features], return_tensors)\n",
    "        task_ids = torch.tensor([f[\"task_ids\"] for f in features], dtype=torch.long)\n",
    "        rtn = {\"input_ids\": batch[\"input_ids\"], \"attention_mask\": batch[\"attention_mask\"], \"labels\": batch[\"labels\"], \"task_ids\": task_ids}\n",
    "        return rtn\n",
    "\n",
    "\n",
    "def get_outputs(model, inputs=None, inputs_embeds=None, decoder_inputs_embeds=None, max_new_tokens=30, device='cuda', text=True,\n",
    "                greedy=False, decoding_args={}):\n",
    "    _decoding_args = {}\n",
    "    if not greedy:\n",
    "        _decoding_args = {\n",
    "            \"temperature\": 0.5,\n",
    "            \"top_p\": 0.95,\n",
    "            \"do_sample\": True,\n",
    "            \"repetition_penalty\": 1.5, #Avoid repetition.\n",
    "            \"early_stopping\": True, #The model can stop before reach the max_length\n",
    "        }\n",
    "        _decoding_args.update(decoding_args)\n",
    "    if inputs_embeds is not None or decoder_inputs_embeds is not None:\n",
    "        outputs = model.generate(\n",
    "            inputs_embeds=None if inputs_embeds is None else inputs_embeds.to(device),\n",
    "            decoder_inputs_embeds=None if decoder_inputs_embeds is None else decoder_inputs_embeds.to(device),\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            **_decoding_args\n",
    "        )    \n",
    "    else:\n",
    "        outputs = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"].to(device),\n",
    "            attention_mask=inputs[\"attention_mask\"].to(device),\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            **_decoding_args\n",
    "        )\n",
    "    if text:\n",
    "        return tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def create_training_arguments(path, learning_rate=0.0035, epochs=6, device='cuda', use_wandb=False):\n",
    "    add_args = {}\n",
    "    if use_wandb:\n",
    "        add_args[\"report_to\"] = \"wandb\"\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=path, # Where the model predictions and checkpoints will be written\n",
    "        use_cpu=device=='cpu', # This is necessary for CPU clusters.\n",
    "        per_device_train_batch_size=16,\n",
    "        auto_find_batch_size=True, # Lowers batch size that will fit into memory automatically\n",
    "        learning_rate=learning_rate, # Higher learning rate than full Fine-Tuning\n",
    "        num_train_epochs=epochs,\n",
    "        logging_steps=epochs//10,\n",
    "        eval_steps=epochs,  # //10\n",
    "        save_steps=epochs,  # //10\n",
    "        metric_for_best_model='loss',  # 'accuracy', # 'loss',\n",
    "        load_best_model_at_end = True,\n",
    "        save_strategy=IntervalStrategy.STEPS,\n",
    "        evaluation_strategy=IntervalStrategy.STEPS,\n",
    "        remove_unused_columns=False,  # important\n",
    "        **add_args\n",
    "    )\n",
    "    return training_args\n",
    "\n",
    "class CustomEarlyStoppingCallback(EarlyStoppingCallback):\n",
    "    def __init__(self):\n",
    "        super()\n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        is_correct = kwargs['metrics']['eval_accuracy'] == 1.\n",
    "        if is_correct:\n",
    "            control.should_training_stop = True\n",
    "\n",
    "def create_trainer(peft_model, training_args, train_dataset, eval_dataset, schedule_free=False,\n",
    "                   unit_norm=False, unit_norm_scale_factor=1.):\n",
    "    add_args = {}\n",
    "    if schedule_free:\n",
    "        if unit_norm:\n",
    "            optimizer = ConstrainedAdamWScheduleFree(\n",
    "                params=peft_model.parameters(),\n",
    "                constrained_params=peft_model.prompt_encoder.parameters(),\n",
    "                lr=training_args.learning_rate,\n",
    "                warmup_steps=100\n",
    "            )\n",
    "        else:\n",
    "            optimizer = schedulefree.AdamWScheduleFree(\n",
    "                peft_model.parameters(),\n",
    "                lr=training_args.learning_rate,\n",
    "                warmup_steps=100,\n",
    "            )\n",
    "        add_args[\"optimizers\"] = (optimizer, None)\n",
    "    elif unit_norm:\n",
    "        optimizer = ConstrainedAdamW(\n",
    "            params=peft_model.parameters(),\n",
    "            constrained_params=peft_model.prompt_encoder.parameters(),\n",
    "            lr=training_args.learning_rate,\n",
    "            scale_factor=unit_norm_scale_factor)\n",
    "        add_args[\"optimizers\"] = (optimizer, None)\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer, model=peft_model) if MODEL_NAME.startswith('t5') else DataCollatorWithPadding(tokenizer)  # DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    "    \n",
    "    # data_collator = DataCollatorForSeq2SeqWithEmbeddings(tokenizer, model=peft_model)\n",
    "    data_collator = CustomDataCollatorForSeq2Seq(tokenizer, model=peft_model)\n",
    "    \n",
    "    def compute_metrics(eval_pred):\n",
    "        _type = \"seq2seq\" if type(eval_pred.predictions) is tuple else \"causal\"\n",
    "        preds = eval_pred.predictions[0] if _type == \"seq2seq\" else eval_pred.predictions\n",
    "        preds = preds.argmax(axis=-1).squeeze()  # greedy\n",
    "        labels = eval_pred.label_ids.squeeze()\n",
    "        if len(preds.shape) != 2:\n",
    "            preds = preds[None, :]\n",
    "            labels = labels[None, :]\n",
    "        is_correct = []\n",
    "        for i in range(len(preds)):\n",
    "            _labels = labels[i]\n",
    "            _preds = preds[i]\n",
    "            _is_correct = _labels[_labels != -100] == _preds[:len(_preds) if _type == \"seq2seq\" else (len(_preds) - 1)][_labels != -100]\n",
    "            is_correct.append((_is_correct.sum() / len(_is_correct)))\n",
    "        return {'accuracy': sum(is_correct) / len(is_correct)}\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=peft_model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        data_collator=data_collator,\n",
    "        callbacks=[CustomEarlyStoppingCallback()], #[EarlyStoppingCallback(early_stopping_patience=1)],  # , early_stopping_threshold=0.2\n",
    "        compute_metrics=compute_metrics,\n",
    "        **add_args\n",
    "    )\n",
    "    return trainer\n",
    "\n",
    "\n",
    "def load_and_set_adapter(directory, name):\n",
    "    loaded_model.load_adapter(directory, adapter_name=name)\n",
    "    loaded_model.set_adapter(name)\n",
    "    return loaded_model\n",
    "\n",
    "\n",
    "def get_virtual_token(foundational_model, tokenizer, hf_dataset, data_idx=0, num_virtual_tokens=1, learning_rate=3e-3, \n",
    "                      epochs=500, save=True, load_saved=False, schedule_free=False, unit_norm=False, unit_norm_scale_factor=1.,\n",
    "                      train_size=1, eval_size=None, use_wandb=False, multi_task=False, low_d=None, out_dir=None):\n",
    "    if use_wandb:\n",
    "        wandb.init()\n",
    "    output_directory =  os.path.join(working_dir, f\"peft_model_{data_idx}\" if out_dir is None else out_dir)\n",
    "    peft_model = None\n",
    "    # Check if the model already exists\n",
    "    if load_saved and os.path.exists(output_directory):\n",
    "        try:\n",
    "            peft_model = PeftModel.from_pretrained(foundational_model,\n",
    "                                                   output_directory,\n",
    "                                                   device_map='auto',\n",
    "                                                   is_trainable=False)\n",
    "            print(\"Loaded saved model\")\n",
    "        except:\n",
    "            print(\"Failed to load saved peft model. Initializing new model.\")\n",
    "    if peft_model is None:\n",
    "        # Load peft model\n",
    "        PromptTuningClass = MultitaskPromptTuningConfig if multi_task else PromptTuningConfig\n",
    "        add_args = {}\n",
    "        if multi_task:\n",
    "            add_args[\"num_tasks\"] = train_size\n",
    "            add_args[\"model_dim\"] = next(foundational_model.get_input_embeddings().parameters()).shape[1]  # foundational_model.model_dim\n",
    "        generation_config = PromptTuningClass(\n",
    "            task_type=TaskType.SEQ_2_SEQ_LM if MODEL_NAME.startswith('t5') else TaskType.CAUSAL_LM,\n",
    "            prompt_tuning_init=PromptTuningInit.RANDOM,  # PromptTuningInit.RANDOM if MODEL_NAME.startswith('t5') else PromptTuningInit.TEXT,  # PromptTuningInit.RANDOM,\n",
    "            prompt_tuning_init_text=tokenizer.decode(hf_dataset[data_idx]['labels'][hf_dataset[data_idx]['labels'].count(-100):], skip_special_tokens=True),  # hf_dataset[data_idx]['prompt'],  # only if using TEXT init\n",
    "            num_virtual_tokens=num_virtual_tokens,\n",
    "            tokenizer_name_or_path=MODEL_NAME, # pre-trained model name\n",
    "            num_transformer_submodules=1,\n",
    "            token_dim=foundational_model.model_dim if low_d is None else low_d,\n",
    "            **add_args\n",
    "        )\n",
    "        peft_model = get_peft_model(foundational_model, generation_config)\n",
    "    print(peft_model.print_trainable_parameters())\n",
    "    \n",
    "    # Create directories to store the models\n",
    "    if not os.path.exists(working_dir):\n",
    "        os.mkdir(working_dir)\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.mkdir(output_directory)\n",
    "\n",
    "    train_dataset = hf_dataset.select(range(data_idx, data_idx+train_size))\n",
    "    if eval_size is None:\n",
    "        eval_dataset = train_dataset\n",
    "    else:\n",
    "        eval_dataset = hf_dataset.select(range(data_idx+train_size, data_idx+train_size+eval_size))\n",
    "    \n",
    "    # Get training args\n",
    "    training_args = create_training_arguments(output_directory, learning_rate, epochs, device=device, use_wandb=use_wandb)\n",
    "    # Get trainer\n",
    "    trainer = create_trainer(peft_model, training_args, \n",
    "                             train_dataset=train_dataset, \n",
    "                             eval_dataset=eval_dataset,\n",
    "                             schedule_free=schedule_free,\n",
    "                             unit_norm=unit_norm, unit_norm_scale_factor=unit_norm_scale_factor)\n",
    "    # Run training\n",
    "    trainer.train()\n",
    "    # Get trained model\n",
    "    peft_model = trainer.model\n",
    "    # Save if required\n",
    "    if save:\n",
    "        peft_model.save_pretrained(output_directory)\n",
    "\n",
    "    # Return virtual token\n",
    "    with torch.no_grad():\n",
    "        if not multi_task:\n",
    "            virtual_token = peft_model.get_prompt(1)\n",
    "        else:\n",
    "            virtual_token = peft_model.get_prompt(train_size, torch.arange(train_size).to(device))\n",
    "\n",
    "    if use_wandb:\n",
    "        wandb.finish()\n",
    "    \n",
    "    return virtual_token, hf_dataset[data_idx]['prompt'], peft_model, trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5d699d-dfd9-4163-b2b3-2312361d1376",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e4b647f-f0d6-493d-96bb-144a97f882b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f9f26c6dbd14f8195b9af06adc92b7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c99db205cd4aae82b2bb916ed972a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9256b828f91f4f6ab6e0dea96af8c71b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c59263ffade146bcb4138869b86bcd0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "global MODEL_NAME\n",
    "MODEL_NAME = \"meta-llama/Llama-2-7b-hf\"  # \"t5-base\"  # \"bigscience/bloomz-560m\" # \"bigscience/bloomz-560m\"  # \"gpt2\"\n",
    "\n",
    "# Load tokenizer    \n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "if MODEL_NAME in ['gpt2', 'meta-llama/Llama-2-7b-hf']:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Load dataset\n",
    "hf_dataset = get_tokenized_dataset(tokenizer, shuffle_input=False)\n",
    "\n",
    "# Load model\n",
    "if MODEL_NAME.startswith('t5'):\n",
    "    config = T5Config.from_pretrained(MODEL_NAME)\n",
    "    config.dropout_rate = 0\n",
    "    foundational_model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME, config=config, device_map='auto')\n",
    "else:\n",
    "    config = LlamaConfig.from_pretrained(MODEL_NAME)\n",
    "    config.attn_dropout = 0\n",
    "    foundational_model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        config=config,\n",
    "        trust_remote_code=True,\n",
    "        torch_dtype=torch.float16 if MODEL_NAME.startswith('meta') else torch.float32,\n",
    "        device_map='auto'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fcd6467d-0e8b-4e69-a947-6a23099a9d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d718d24740e7453886a7ee6162374441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba686bc5f4a24e289a045bbd08f98767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf_dataset = get_tokenized_dataset(tokenizer, shuffle_input=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e163594-3d0d-4d2a-bca2-ef5be0e62732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the input_ids of the dataset\n",
    "# hf_dataset = get_tokenized_dataset(tokenizer, shuffle_input=True, seed=19, constant_input=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9260fdb3-e3d5-4193-837d-d4561badd4a6",
   "metadata": {},
   "source": [
    "# Soft-prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ac5d139-1819-409b-b61b-b65df2d6fd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp peft_model/checkpoint-250000/* peft_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fcc729a4-dd35-4382-8e77-cc35d1b9c73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81482617-9a92-47fe-8664-e46ab130c9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 42,070 || all params: 6,738,457,686 || trainable%: 0.000624326840953617\n"
     ]
    }
   ],
   "source": [
    "# peft_model = PeftModel.from_pretrained(foundational_model,\n",
    "#                                        'peft_model/checkpoint-440',\n",
    "#                                        device_map='auto',\n",
    "#                                        is_trainable=False)\n",
    "# peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f15276-f13c-4f9e-bbb7-6845a17bc63b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/workspace/dagarwal_umass_edu-lapeft-bayesopt/lapeft-bayesopt/notebooks/wandb/run-20240529_025810-hd10ms4y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dhdhagar/lapeft-bayesopt-notebooks_notebooks/runs/hd10ms4y' target=\"_blank\">decent-hill-61</a></strong> to <a href='https://wandb.ai/dhdhagar/lapeft-bayesopt-notebooks_notebooks' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dhdhagar/lapeft-bayesopt-notebooks_notebooks' target=\"_blank\">https://wandb.ai/dhdhagar/lapeft-bayesopt-notebooks_notebooks</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dhdhagar/lapeft-bayesopt-notebooks_notebooks/runs/hd10ms4y' target=\"_blank\">https://wandb.ai/dhdhagar/lapeft-bayesopt-notebooks_notebooks/runs/hd10ms4y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load saved peft model. Initializing new model.\n",
      "trainable params: 62,970 || all params: 6,738,478,586 || trainable%: 0.0009344839372321781\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53173' max='250000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 53173/250000 2:05:43 < 7:45:25, 7.05 it/s, Epoch 425.38/2000]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.651300</td>\n",
       "      <td>3.623791</td>\n",
       "      <td>0.387736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>3.261100</td>\n",
       "      <td>3.250265</td>\n",
       "      <td>0.463044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>3.009400</td>\n",
       "      <td>3.002292</td>\n",
       "      <td>0.499336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>2.776100</td>\n",
       "      <td>2.761252</td>\n",
       "      <td>0.533202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>2.532500</td>\n",
       "      <td>2.523703</td>\n",
       "      <td>0.567790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>2.324400</td>\n",
       "      <td>2.305750</td>\n",
       "      <td>0.606715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>2.117700</td>\n",
       "      <td>2.106028</td>\n",
       "      <td>0.637574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>1.937000</td>\n",
       "      <td>1.918895</td>\n",
       "      <td>0.671174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>1.769900</td>\n",
       "      <td>1.756878</td>\n",
       "      <td>0.699257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>1.603500</td>\n",
       "      <td>1.589105</td>\n",
       "      <td>0.734857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>1.480700</td>\n",
       "      <td>1.451165</td>\n",
       "      <td>0.760254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>1.334500</td>\n",
       "      <td>1.324028</td>\n",
       "      <td>0.785220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>1.224000</td>\n",
       "      <td>1.212148</td>\n",
       "      <td>0.807265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>1.127800</td>\n",
       "      <td>1.109409</td>\n",
       "      <td>0.825812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>1.020200</td>\n",
       "      <td>1.015879</td>\n",
       "      <td>0.843275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.951600</td>\n",
       "      <td>0.933641</td>\n",
       "      <td>0.859833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.854200</td>\n",
       "      <td>0.852774</td>\n",
       "      <td>0.874150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.791900</td>\n",
       "      <td>0.783301</td>\n",
       "      <td>0.886250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.743500</td>\n",
       "      <td>0.725719</td>\n",
       "      <td>0.897383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.689000</td>\n",
       "      <td>0.671612</td>\n",
       "      <td>0.907400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.636100</td>\n",
       "      <td>0.620074</td>\n",
       "      <td>0.916017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.593200</td>\n",
       "      <td>0.573612</td>\n",
       "      <td>0.925208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.552400</td>\n",
       "      <td>0.534842</td>\n",
       "      <td>0.929892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.509100</td>\n",
       "      <td>0.496866</td>\n",
       "      <td>0.938783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.480100</td>\n",
       "      <td>0.461566</td>\n",
       "      <td>0.942500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>0.443500</td>\n",
       "      <td>0.431998</td>\n",
       "      <td>0.947350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get vtoken\n",
    "vtoken, prompt, peft_model, trainer = get_virtual_token(foundational_model, tokenizer, hf_dataset, data_idx=0, \n",
    "                                                        num_virtual_tokens=1, learning_rate=1e-2 if MODEL_NAME.startswith('t5') else 3e-4, epochs=2000, \n",
    "                                                        schedule_free=False, unit_norm=True, # unit_norm_scale_factor=feats.norm(dim=1).mean(),  # 1.,\n",
    "                                                        save=False, load_saved=True, train_size=2000, eval_size=None, use_wandb=True, multi_task=True, low_d=10,\n",
    "                                                        out_dir=\"peft_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b1deba-ee60-4909-bd70-e19d50d31a58",
   "metadata": {},
   "source": [
    "### Generate vtoken output and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81eaddbd-1f93-43b8-8745-05ab0442c120",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    projection_matrix = peft_model.prompt_encoder.default.projection_matrix\n",
    "    lowd_vtoken = peft_model.prompt_encoder.default.prefix_task_cols @ peft_model.prompt_encoder.default.prefix_task_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a37b3280-33ef-465b-acec-f3714a350502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(lowd_vtoken.norm(dim=-1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69e4724b-04f3-4a1d-a33a-b88fbfcd1224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(64., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(projection_matrix.norm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "593833e3-5d45-4e5e-b3ca-92d82df04f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(20.7313, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print((lowd_vtoken @ projection_matrix).norm(dim=-1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe252e58-f489-440a-9644-7e72de29b3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if in word2vec vocab\n",
    "import gensim.downloader\n",
    "vectors = gensim.downloader.load('word2vec-google-news-300')\n",
    "len(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95fcf419-29bc-4525-9ff2-0a7329cfc177",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec45d967d594161920578aced16bc33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 TARGET: computer PRED: computer\n",
      "1 TARGET: laptop PRED: laptop\n",
      "2 TARGET: photocopier PRED: photocopier\n",
      "3 TARGET: machine PRED: machine\n",
      "4 TARGET: notebook PRED: notebook\n",
      "5 TARGET: microprocessor PRED: microprocessor\n",
      "6 TARGET: internet PRED: internet\n",
      "7 TARGET: electronic PRED: electronic\n",
      "8 TARGET: lab PRED: lab\n",
      "9 TARGET: gameboy PRED: gameboy\n",
      "10 TARGET: digital PRED: digital\n",
      "11 TARGET: fingerprint PRED: fingerprint\n",
      "12 TARGET: phone PRED: phone\n",
      "13 TARGET: geek PRED: geek\n",
      "14 TARGET: synthesizer PRED: synthesizer\n",
      "15 TARGET: diskette PRED: diskette\n",
      "16 TARGET: robot PRED: robot\n",
      "17 TARGET: appliance PRED: appliance\n",
      "18 TARGET: worm PRED: worm\n",
      "19 TARGET: coding PRED: coding\n",
      "20 TARGET: codebook PRED: codebook\n",
      "21 TARGET: scanner PRED: scanner\n",
      "22 TARGET: library PRED: library\n",
      "23 TARGET: abacus PRED: abacus\n",
      "24 TARGET: snooper PRED: snooper\n",
      "25 TARGET: simulation PRED: simulation\n",
      "26 TARGET: oscilloscope PRED: oscilloscope\n",
      "27 TARGET: corkboard PRED: corkboard\n",
      "28 TARGET: macbook PRED: macbook\n",
      "29 TARGET: dialer PRED: dialer\n",
      "30 TARGET: multiprocessor PRED: multiprocessor\n",
      "31 TARGET: schoolwork PRED: schoolwork\n",
      "32 TARGET: camcorder PRED: camcorder\n",
      "33 TARGET: pencil PRED: pencil\n",
      "34 TARGET: satellite PRED: satellite\n",
      "35 TARGET: circuitry PRED: circuitry\n",
      "36 TARGET: controller PRED: controller\n",
      "37 TARGET: stylus PRED: stylus\n",
      "38 TARGET: workbench PRED: workbench\n",
      "39 TARGET: tablet PRED: boyfriend\n",
      "40 TARGET: eavesdropper PRED: eavesdropper\n",
      "41 TARGET: thermostat PRED: thermostat\n",
      "42 TARGET: dishwasher PRED: dishwasher\n",
      "43 TARGET: blackboard PRED: blackboard\n",
      "44 TARGET: photoshop PRED: photoshop\n",
      "45 TARGET: eraser PRED: eraser\n",
      "46 TARGET: cookie PRED: cookie\n",
      "47 TARGET: airplane PRED: airplane\n",
      "48 TARGET: copy PRED: copy\n",
      "49 TARGET: web PRED: web\n",
      "50 TARGET: gamer PRED: gamer\n",
      "51 TARGET: spy PRED: spy\n",
      "52 TARGET: handset PRED: handset\n",
      "53 TARGET: refridgerator PRED: refridgerator\n",
      "54 TARGET: scan PRED: scan\n",
      "55 TARGET: engineer PRED: engineer\n",
      "56 TARGET: treadmill PRED: treadmill\n",
      "57 TARGET: glucometer PRED: glucometer\n",
      "58 TARGET: refrigerator PRED: refrigerator\n",
      "59 TARGET: homebrew PRED: homebrew\n",
      "60 TARGET: stopwatch PRED: stopwatch\n",
      "61 TARGET: toaster PRED: toaster\n",
      "62 TARGET: preschooler PRED: preschool\n",
      "63 TARGET: hardcopy PRED: hardcopy\n",
      "64 TARGET: kiosk PRED: kiosk\n",
      "65 TARGET: auto PRED: auto\n",
      "66 TARGET: tv PRED: tv\n",
      "67 TARGET: storage PRED: storage\n",
      "68 TARGET: sleuth PRED: sleuth\n",
      "69 TARGET: turntable PRED: turntable\n",
      "70 TARGET: car PRED: car\n",
      "71 TARGET: plasma PRED: plasma\n",
      "72 TARGET: transmitter PRED: transmitter\n",
      "73 TARGET: wheelchair PRED: wheelchair\n",
      "74 TARGET: wizard PRED: wizard\n",
      "75 TARGET: wallpaper PRED: wallpaper\n",
      "76 TARGET: wires PRED: wires\n",
      "77 TARGET: theater PRED: theater\n",
      "78 TARGET: beeper PRED: unlock\n",
      "79 TARGET: instrument PRED: instrument\n",
      "80 TARGET: transcriber PRED: transcriber\n",
      "81 TARGET: prosthetics PRED: prosthetics\n",
      "82 TARGET: cashbook PRED: cashbook\n",
      "83 TARGET: dorm PRED: dorm\n",
      "84 TARGET: bicycle PRED: bicycle\n",
      "85 TARGET: tape PRED: tape\n",
      "86 TARGET: chat PRED: chat\n",
      "87 TARGET: stationery PRED: stationery\n",
      "88 TARGET: programming PRED: programming\n",
      "89 TARGET: recliner PRED: recliner\n",
      "90 TARGET: diagram PRED: diagram\n",
      "91 TARGET: scientist PRED: scientist\n",
      "92 TARGET: dresser PRED: dresser\n",
      "93 TARGET: transistor PRED: transistor\n",
      "94 TARGET: screener PRED: screener\n",
      "95 TARGET: receptionist PRED: receptionist\n",
      "96 TARGET: passport PRED: passport\n",
      "97 TARGET: elementary PRED: elementary\n",
      "98 TARGET: mahjong PRED: mahjong\n",
      "99 TARGET: neuroscientist PRED: neuroscientist\n",
      "Accuracy: 0.97 (n=100)\n",
      "Valid: 1.0 (n=100)\n",
      "New: 0.03 (n=100)\n"
     ]
    }
   ],
   "source": [
    "multi_task = True\n",
    "correct, valid, invalid, new = [], [], [], []\n",
    "vtoken_outputs = []\n",
    "n = 100\n",
    "for idx in tqdm(range(n)):\n",
    "    # _vtoken = vtoken[None, idx] if multi_task else vtoken\n",
    "    with torch.no_grad():\n",
    "        # rand_vtoken = torch.rand((1, 10)).to(device) @ projection_matrix\n",
    "        perturbation = ((torch.rand((1, 10))-0.5)*(torch.rand(10) < 0) * 3e-1).to(device)\n",
    "        rand_vtoken = (lowd_vtoken[idx] + perturbation) @ projection_matrix\n",
    "    _vtoken = rand_vtoken[None, :]\n",
    "    # Add text tokens\n",
    "    prompt_embed = get_prompt_embed(hf_dataset, foundational_model, tokenizer,) \n",
    "                                    # custom_prompt=\"The task is to find a hidden test word by guessing new words. What is your next guess?\")\n",
    "    _vtoken = torch.cat((_vtoken, prompt_embed), dim=1)  # prepend vtoken to prompt embed\n",
    "    # _vtoken = torch.cat((prompt_embed, _vtoken), dim=1)  # append vtoken to prompt embed\n",
    "    vtoken_output = get_outputs(foundational_model,\n",
    "                                inputs_embeds=_vtoken.type(foundational_model.dtype),\n",
    "                                device=device, text=True, greedy=True, decoding_args={\"top_p\": 0.95, \"temperature\": 0.4})[0]\n",
    "    vtoken_outputs.append(vtoken_output.strip().lower())\n",
    "    \n",
    "    print(idx, f'TARGET: {hf_dataset[idx][\"target\"]}', f'PRED: {vtoken_outputs[-1]}')\n",
    "    \n",
    "    if hf_dataset[idx][\"target\"] == vtoken_outputs[-1]:\n",
    "        correct.append(hf_dataset[idx][\"target\"])\n",
    "    \n",
    "    # Check if in word2vec vocab\n",
    "    if vectors.get_index(vtoken_outputs[-1], -1000) != -1000:\n",
    "        valid.append((hf_dataset[idx][\"target\"], vtoken_outputs[-1]))\n",
    "        if vtoken_outputs[-1] not in targets:\n",
    "            new.append((hf_dataset[idx][\"target\"], vtoken_outputs[-1]))\n",
    "    else:\n",
    "        invalid.append((hf_dataset[idx][\"target\"], vtoken_outputs[-1]))\n",
    "print(f\"Accuracy: {len(correct)/n} (n={n})\")\n",
    "print(f\"Valid: {len(valid)/n} (n={n})\")\n",
    "print(f\"New: {len(new)/n} (n={n})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01553097-f553-494c-93ea-b551f575b869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tablet', 'boyfriend'), ('preschooler', 'preschool'), ('beeper', 'unlock')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8402f856-2c4a-4201-bda7-142b26ded840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word_outputs = [v.strip().lower() for v in vtoken_outputs]\n",
    "# word_outputs = [w for w in word_outputs if len(w.split()) == 1 and all(not w.startswith(char) for char in ['-','_',\"'\",'\"',')','(','!','?',',',':',';'])]\n",
    "# len(word_outputs)\n",
    "# word_outputs_w2v = [w for w in word_outputs if vectors.get_index(w, -1000) != -1000]\n",
    "# len(word_outputs_w2v)\n",
    "# word_outputs_w2v_new = [w for w in word_outputs_w2v if w not in targets]\n",
    "# len(word_outputs_w2v_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "26108090-48c6-498d-bc5b-566768582b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "344"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect examples\n",
    "filtered = [(n[0],n[1].strip()) for n in not_in_target_set]\n",
    "filtered = [n for n in not_in_target_set if len(n[1]) > 2 and n[1].lower() not in ['the'] and not n[1].startswith('-') and not n[1].startswith('.') and not n[1].startswith('_')]\n",
    "print(len(filtered))\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "eed6f37d-9c24-4023-9667-58367a517c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate vector similarities\n",
    "cos = cosine_similarity(lowd_vtoken.squeeze(), lowd_vtoken.squeeze()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a3c5a683-529e-46c8-8238-981e91c534b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(311., device='cuda:0')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(cos, 10).indices.type(torch.float).sum()  # should be n*(n+1)/2 if ranked exactly in word2vec order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6ce1e270-adfd-491a-ae0e-e6b30cd0d046",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>computer</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>microprocessor</td>\n",
       "      <td>0.476398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>handbook</td>\n",
       "      <td>0.187190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>game</td>\n",
       "      <td>0.258705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>gamer</td>\n",
       "      <td>0.349844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>reporter</td>\n",
       "      <td>0.160982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>electrochemist</td>\n",
       "      <td>0.301648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>nursemaid</td>\n",
       "      <td>0.195729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>observatory</td>\n",
       "      <td>0.293139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>excavator</td>\n",
       "      <td>0.293857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Words  Similarity\n",
       "0           computer    1.000000\n",
       "5     microprocessor    0.476398\n",
       "914         handbook    0.187190\n",
       "278             game    0.258705\n",
       "50             gamer    0.349844\n",
       "1263        reporter    0.160982\n",
       "115   electrochemist    0.301648\n",
       "811        nursemaid    0.195729\n",
       "134      observatory    0.293139\n",
       "131        excavator    0.293857"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.iloc[torch.topk(cos, 10).indices.cpu().numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fcb99904-ab8e-4b24-bdd7-2fc355668d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEAT_PATH=\"../cache/word2vec-2000/computer/computer_instruction_average_t5-base_feats.bin\"\n",
    "avg_feats = torch.load(FEAT_PATH)\n",
    "cos2 = cosine_similarity(avg_feats.squeeze(), avg_feats.squeeze()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "322065ca-55c8-4616-8bf6-d6b4b319e7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.8000)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(cos2, 5).indices.type(torch.float).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "78f86e7a-efbb-4b58-b8b8-356420c917a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>computer</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>machine</td>\n",
       "      <td>0.491536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>scanner</td>\n",
       "      <td>0.403824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>robot</td>\n",
       "      <td>0.417509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>web</td>\n",
       "      <td>0.349953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>poster</td>\n",
       "      <td>0.178068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>electronic</td>\n",
       "      <td>0.464129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>movie</td>\n",
       "      <td>0.293668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>program</td>\n",
       "      <td>0.217862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>table</td>\n",
       "      <td>0.205104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Words  Similarity\n",
       "0       computer    1.000000\n",
       "3        machine    0.491536\n",
       "21       scanner    0.403824\n",
       "16         robot    0.417509\n",
       "49           web    0.349953\n",
       "1028      poster    0.178068\n",
       "7     electronic    0.464129\n",
       "132        movie    0.293668\n",
       "564      program    0.217862\n",
       "696        table    0.205104"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.iloc[torch.topk(cos2, 10).indices.cpu().numpy()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717cdbe5-0abb-438a-be47-a72f6ebd16ad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Perturb vtoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1bd22fc9-91f3-4f58-8fb9-5bc9c72dd99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = torch.rand(vtoken.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a1fd8f2c-f33c-43bb-bcde-20c425934ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.zeros(vtoken.shape)\n",
    "mask[:, :, :75] = 1\n",
    "mask = mask[:, :, torch.randperm(mask.nelement())]\n",
    "new_vtoken = (vtoken + (rand*mask).to(device) * 1000) * 1.\n",
    "# get_outputs(foundational_model, \n",
    "#             inputs_embeds=new_vtoken, \n",
    "#             # decoder_inputs_embeds=decoder_inputs_embeds[:, :-10, :]*100,\n",
    "#             device=device, text=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24146d4-921d-4569-bc1b-f4671eb3a64a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Combine vtoken and textual prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "71c8f04e-aff9-4f35-8356-af695a5c3663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 103, 768])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeds = foundational_model.get_input_embeddings()\n",
    "for p in token_embeds.parameters():\n",
    "    break\n",
    "# Based on prompt text\n",
    "# _prompt = \" \".join(prompt.split()[:-1])  # Everything except pwd/chmod\n",
    "# prompt_embed = p[tokenizer(_prompt, return_tensors='pt')['input_ids'][0]][None, :, :]\n",
    "\n",
    "# Based on prompt input_ids\n",
    "if MODEL_NAME.startswith('t5'):\n",
    "    prompt_input_ids = hf_dataset[0]['input_ids']  # encoder input\n",
    "else:\n",
    "    prompt_input_ids = hf_dataset[0]['input_ids'][:hf_dataset[0]['labels'].count(-100)]  # inputs for which no predictions need to be made\n",
    "_prompt = tokenizer.decode(prompt_input_ids, skip_special_tokens=True)\n",
    "prompt_embed = p[prompt_input_ids][None, :, :]\n",
    "\n",
    "# vtoken_norm_and_scaled = torch.nn.functional.normalize(vtoken)*prompt_embed.norm(dim=-1).mean()\n",
    "vtoken_plus_text = torch.cat((vtoken, prompt_embed), dim=1)  # prepend vtoken to prompt embed\n",
    "vtoken_plus_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5bfd9ec1-1689-4478-9db9-1c09bb940701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "I want you to act as a linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets like this. my first command is\n",
      "\n",
      "Vtoken:\n",
      "pwd: I want you to act as a linux terminal. type commands and you will reply with what the terminal should show. do not write explanations. do not type commands unless I instruct you to do so. my first command is like this, so i will type it in curly brackets like this. my second command is like this, so i will type it into curly brackets like this. my last command is like this\n"
     ]
    }
   ],
   "source": [
    "# Generate vtoken output and compare\n",
    "vtoken_output = get_outputs(foundational_model, inputs_embeds=vtoken_plus_text.type(foundational_model.dtype),\n",
    "                            device=device, text=True, greedy=False)[0]\n",
    "print(f'Prompt:\\n{_prompt}\\n')\n",
    "print(f'Vtoken:\\n{vtoken_output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0a145bc0-7f16-4c13-8e54-813c81d045c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(348.1645, device='cuda:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_embed.norm(dim=-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9ffb7f05-8eb1-49c3-8265-2956f73061a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(96.4136, device='cuda:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_embed.norm(dim=-1).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4dcb903e-e75b-4eb3-adc3-4e2e7ab15efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(228.3652, device='cuda:0')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_embed.norm(dim=-1).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a7ae0111-e8f9-46ef-a862-af46ff30735f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(532.9974, device='cuda:0')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_embed.norm(dim=-1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c1339c74-7117-42a6-a821-835ea570757b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., device='cuda:0') tensor(1.6794e-05, device='cuda:0') tensor(0.0361, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(vtoken.norm(), vtoken.mean(), vtoken.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1721755-d936-48e4-996f-2e25afb157d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Comparing different vtokens"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2f88c1c9-7725-4961-b59d-cebd4e201f18",
   "metadata": {},
   "source": [
    "# Shuffled Prompt (seed=17)\n",
    " tell commands code not unique should inlike inside and to with. command the need, not reply english linux will I what want nothing you terminal block you as putting unless reply so first. else do when so terminal want you show onely} do to write.I this to, { commands you and do by you instruct is a text something i to. act explanations I will I. terminal inside with type the brackets i. type only my cur do output will"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f8a15a6a-5ad1-40fc-ad35-74b99b9c8775",
   "metadata": {},
   "source": [
    "# Shuffled Prompt (seed=18)\n",
    " show youlike you nothing reply I when cur i is. unique to terminal this the command and tell should} terminal english by not need you brackets commands do what willI in to and. i instruct output, inside one putting reply commands code so inside linux with something explanations so. with I type first you act unless do do, to do a want terminal { not the. you. to will I only want type else as my will. text block writely\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cb06f8ab-f0cb-4757-8b51-3fc3d1457c13",
   "metadata": {},
   "source": [
    "# Shuffled Prompt (seed=19)\n",
    "} as tell you to I do. you unique do with by terminal commands text type and output puttingly block you is. something and to. I not act not a want want need brackets. you explanations first to nothing what one the I, you. will commands when i. type terminal else with code reply should,I i my write to will this only terminal will unless command so show instruct english linux do cur reply so inside do in thelike { inside\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a39e5d29-f80b-4088-959e-88b57f82e953",
   "metadata": {},
   "source": [
    "# Constant Prompt (0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60ea6da6-44b7-4029-8d87-8f2ffe314e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "vtoken1 = vtoken  # Unshuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "22d3809b-7641-4a24-ac11-9630e3434cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "vtoken2 = vtoken  # Shuffled (seed=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3849f7cf-5f31-46ca-b94f-4c15f12e921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vtoken3 = vtoken  # Shuffled (seed=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4dc9cd2d-cd3c-4704-84f8-72e5c67d0848",
   "metadata": {},
   "outputs": [],
   "source": [
    "vtoken4 = vtoken  # Shuffled (seed=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e87d9ef0-642f-4e28-9dfc-ee3523fc4126",
   "metadata": {},
   "outputs": [],
   "source": [
    "vtoken5 = vtoken  # Constant (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2902ed2a-9955-4409-a465-9a21f940f1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[925.2473]]], device='cuda:0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cdist(vtoken1, vtoken2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "93384cfc-4e60-47c8-b28b-4b5c4aa04d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[867.6586]]], device='cuda:0')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cdist(vtoken1, vtoken3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8a89214b-0466-4e62-8d66-d65923f79b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1069.6093]]], device='cuda:0')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cdist(vtoken1, vtoken4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2f3edd69-ed91-4016-b337-a944f5105119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1095.5792]]], device='cuda:0')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cdist(vtoken1, vtoken5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c2f1d85a-6fdb-469a-a82f-2367237ebcd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[427.0382]]], device='cuda:0')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cdist(vtoken2, vtoken3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b1fb0974-65d3-4d9f-a286-d8acaaf190da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[670.3230]]], device='cuda:0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cdist(vtoken2, vtoken4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "848349d7-0e1f-49ce-a159-7f65df9643db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[888.1259]]], device='cuda:0')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cdist(vtoken2, vtoken5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ac8c398d-6726-4be4-bc5d-59582d757c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[678.1097]]], device='cuda:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cdist(vtoken3, vtoken4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9e1cd18c-9ac5-458c-a4a2-a827fe13dee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[891.1073]]], device='cuda:0')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cdist(vtoken3, vtoken5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5e8d1423-f4f8-4fe7-b8e4-eedcb5bb26d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1059.0133]]], device='cuda:0')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cdist(vtoken4, vtoken5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc57046-484c-434c-9ec3-a3fab64f8ebd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Check output with peft model using textual prompt (t5-only)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ea1b30-40e5-4cec-8f46-dd3863cb8348",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa4b39f-83c5-465c-a50c-a71e07bd0943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR T5 models only\n",
    "input_tokenized = tokenizer(\"Instruction\", return_tensors='pt')\n",
    "input_tokenized = {**input_tokenized, \"attention_mask\": input_tokenized[\"attention_mask\"]*0}\n",
    "vtoken_output = get_outputs(peft_model, inputs=input_tokenized, device=device, text=True)[0]\n",
    "print(f'Prompt:\\n{prompt}\\n')\n",
    "print(f'Vtoken:\\n{vtoken_output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0703952-d267-44ba-b520-6b01e0d1fb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEAT_PATH=\"../cache/word2vec-2000/computer/computer_word_average_llama-2-7b_feats.bin\"\n",
    "features = torch.load(FEAT_PATH)\n",
    "# warm_start_idxs = np.array([669, 1705, 814, 810, 1441]) - 1\n",
    "# warm_start_features = features[warm_start_idxs]\n",
    "# warm_start_norm_mean = torch.linalg.vector_norm(warm_start_features, dim=1).mean().item()\n",
    "# full_set_norm_mean = torch.linalg.vector_norm(features, dim=1).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90d6194b-7495-4f06-a12d-a418c5d96749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 4096])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "836ebde5-3197-42e0-818b-c52ef7fc901c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import cosine_similarity\n",
    "cos = cosine_similarity(features, features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63d68a16-2df7-4b64-83fb-d94398a25dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([1.0000, 0.9151, 0.9067, 0.8878, 0.8868, 0.8857, 0.8855, 0.8834, 0.8818,\n",
       "        0.8815, 0.8809, 0.8785, 0.8775, 0.8766, 0.8755, 0.8752, 0.8748, 0.8746,\n",
       "        0.8746, 0.8738, 0.8717, 0.8709, 0.8701, 0.8689, 0.8685, 0.8675, 0.8670,\n",
       "        0.8669, 0.8667, 0.8664]),\n",
       "indices=tensor([   0,    1,    6,   55,  233,   88,   34,   16,  432,  250,  312,    7,\n",
       "          25,  663,  226,    3, 1889,   12,  276,  909,  476,  707,  379,  588,\n",
       "         246,  919, 1052,  784,  365,  197]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(cos, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e940da1e-3987-4b3e-894f-8297b22c06f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_0 = features[0]\n",
    "feature_0_norm = feature_0.norm()\n",
    "feature_0_normalized = feature_0 / feature_0_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b540a3e-b2eb-4821-a67b-f5a1757cafed",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_mix = features[1992]\n",
    "feature_mix_norm = feature_mix.norm()\n",
    "feature_mix_normalized = feature_mix / feature_mix_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a47c6f1a-26d8-40cd-a3fc-3b8065505f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embeds = foundational_model.get_input_embeddings()\n",
    "for p in token_embeds.parameters():\n",
    "    break\n",
    "# Based on prompt text\n",
    "_prompt = \"The task is to find a hidden test word by guessing new words. What is your next guess?\"\n",
    "prompt_embed = p[tokenizer(_prompt, return_tensors='pt')['input_ids'][0]][None, :, :]\n",
    "prompt_embed_norm_mean = prompt_embed.norm(dim=2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee78a63e-bfdb-48d7-b168-b7fee2acda90",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 4096 but got size 768 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m rand \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mnormalize(torch\u001b[38;5;241m.\u001b[39mrand(feature_0_normalized\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      3\u001b[0m vtoken \u001b[38;5;241m=\u001b[39m ((feature_0_normalized\u001b[38;5;241m.\u001b[39mcuda()) \u001b[38;5;241m*\u001b[39m prompt_embed_norm_mean)[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, :]\u001b[38;5;241m.\u001b[39mcuda()  \u001b[38;5;66;03m# * rand  # * warm_start_norm_mean\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m vtoken_plus_text \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((vtoken, prompt_embed), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# prepend vtoken to prompt embed\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Generate vtoken output\u001b[39;00m\n\u001b[1;32m      7\u001b[0m vtoken_output \u001b[38;5;241m=\u001b[39m get_outputs(foundational_model, inputs_embeds\u001b[38;5;241m=\u001b[39mvtoken_plus_text\u001b[38;5;241m.\u001b[39mtype(foundational_model\u001b[38;5;241m.\u001b[39mdtype),\n\u001b[1;32m      8\u001b[0m                             device\u001b[38;5;241m=\u001b[39mdevice, text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 4096 but got size 768 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "for i in range(1, 1000, 1000):\n",
    "    rand = torch.nn.functional.normalize(torch.rand(feature_0_normalized.shape)*2-1, dim=0)\n",
    "    vtoken = ((feature_0_normalized.cuda()) * prompt_embed_norm_mean)[None, None, :].cuda()  # * rand  # * warm_start_norm_mean\n",
    "    vtoken_plus_text = torch.cat((vtoken, prompt_embed), dim=1)  # prepend vtoken to prompt embed\n",
    "    \n",
    "    # Generate vtoken output\n",
    "    vtoken_output = get_outputs(foundational_model, inputs_embeds=vtoken_plus_text.type(foundational_model.dtype),\n",
    "                                device=device, text=True)[0]\n",
    "    print(f'{vtoken_output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9659a372-6d84-448c-869f-e5e168752946",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowd_vtoken = peft_model.prompt_encoder.default.prefix_task_cols @ peft_model.prompt_encoder.default.prefix_task_rows\n",
    "cos = cosine_similarity(lowd_vtoken.squeeze(), lowd_vtoken.squeeze()[0])\n",
    "torch.topk(cos, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47f3517-3ef0-464a-ab23-057928cabdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos2 = cosine_similarity(feats[:100], feats[:100][0])\n",
    "torch.topk(cos2, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ab89e9-42fa-4387-b9ea-73ccd9ddc065",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos3 = cosine_similarity(vtoken.squeeze(), vtoken.squeeze()[0])\n",
    "torch.topk(cos3, k=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
